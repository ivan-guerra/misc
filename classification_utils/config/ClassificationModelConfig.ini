# Each entry below represents one of the supported models and their
# corresponding hyperparameters. Comment out/remove those models you are
# uninterested in running. Reference the sklearn docs for the model(s) of
# interest to learn what are valid values for each parameter. Don't see
# the model you want or is the model missing a hyperparameter you really
# want to try? Feel free to edit the source code or put in a feature request
# on the project page.

[LogisticRegression]
penalty  = l1,l2
tol      = 1e-4
C        = 0.1,1.0
solver   = liblinear
max_iter = 10000

[RidgeClassifier]
alpha    = 0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0
tol      = 1e-2,1e-3,1e-4
solver   = auto,svd,cholesky,lsqr,sparse_cg
max_iter = 10000

[KNN]
n_neighbors = 1,2,3,4,5
metric      = euclidean,manhattan
weights     = uniform,distance
algorithm   = auto,ball_tree,kd_tree,brute
p           = 1,2,3

[SupportVectorMachine]
C           = 100,10,1.0,0.1,0.001
kernel      = linear,poly,rbf,sigmoid
degree      = 2,3,4,5
gamma       = scale,auto
coef0       = 0.0
shrinking   = True,False
probability = True,False
max_iter    = 10000
break_ties  = True,False

[BaggedDecisionTrees]
n_estimators       = 10,100,500
max_features       = 1.0
bootstrap          = True
bootstrap_features = False
oob_score          = False

[RandomForest]
max_features = sqrt,log2
n_estimators = 10,100,500

[StochasticGradientBoosting]
learning_rate = 0.001,0.01,0.1
n_estimators  = 10,100,500
subsample     = 0.5,0.7,1.0
max_depth     = 3,7,9
